# ðŸš€ Sales Data Analysis System - Quick Start Guide

## Step 1: Create Project Structure

```bash
mkdir Sales_Data_Analysis_System
cd Sales_Data_Analysis_System

# Create subdirectories
mkdir -p data queries python insights/charts output
```

## Step 2: Download All Files

Place the downloaded files in the correct locations:

```
Sales_Data_Analysis_System/
â”œâ”€â”€ schema.sql                    # Database schema
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ README.md                     # Full documentation
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw_sales_data.csv       # Sample data (provided)
â”œâ”€â”€ queries/
â”‚   â””â”€â”€ queries.json             # SQL queries config
â””â”€â”€ python/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config.py                # Database credentials
    â”œâ”€â”€ db.py                    # Database manager
    â”œâ”€â”€ query_loader.py          # Query loader
    â”œâ”€â”€ query_executor.py        # Query executor
    â”œâ”€â”€ analysis.py              # Analysis engine
    â”œâ”€â”€ visualization.py         # Visualization
    â””â”€â”€ main.py                  # Main app
```

## Step 3: Set Up MySQL Database

### Option A: Command Line (Recommended)

```bash
# Login to MySQL and run schema
mysql -u root -p < schema.sql
```

### Option B: MySQL Workbench

1. Open MySQL Workbench
2. Create new query tab
3. Copy contents of `schema.sql`
4. Execute (Ctrl+Enter)

### Verify Setup

```sql
USE sales_analytics;
SHOW TABLES;
-- Should show: customers, products, sales
```

## Step 4: Update Database Credentials

Edit `python/config.py`:

```python
DB_HOST = 'localhost'
DB_USER = 'root'
DB_PASSWORD = 'your_mysql_password'  # â† CHANGE THIS
DB_NAME = 'sales_analytics'
DB_PORT = 3306
```

## Step 5: Install Python Dependencies

```bash
pip install -r requirements.txt
```

**Expected output:**
```
Successfully installed mysql-connector-python pandas numpy matplotlib seaborn python-dotenv
```

## Step 6: Load Sample Data

```bash
cd python
python main.py --load-sample-data
```

**Expected output:**
```
âœ“ Connected to MySQL database: sales_analytics
ðŸ“¥ Loading sample data...
  Loading customers...
âœ“ Inserted 50 rows into customers
  Loading products...
âœ“ Inserted 20 rows into products
  Loading sales transactions...
âœ“ Inserted 300 rows into sales
âœ“ Sample data loaded successfully!
```

## Step 7: Run Complete Analysis

```bash
python main.py
```

**Expected output:**
```
============================================================
ðŸš€ Starting Sales Data Analysis
============================================================

â–¶ï¸  Running: monthly_sales
âœ“ CSV saved: monthly_sales.csv
  month    total_sales
0  2024-01  245633.24
1  2024-02  278444.32
...

â–¶ï¸  Running: top_products
âœ“ CSV saved: top_products.csv
  product_name  total_units
0  Laptop Pro        28
1  Monitor 4K        24
...

[More analyses...]

âœ“ Analysis Complete!

ðŸ“Š Output Location: /path/to/output
ðŸ“ˆ Charts Location: /path/to/insights/charts
ðŸ“„ Insights Location: /path/to/insights/insights.md
```

## Step 8: View Results

### CSV Reports
```bash
open output/monthly_sales.csv
open output/top_products.csv
# ... other CSV files
```

### Charts
```bash
open insights/charts/monthly_sales.png
open insights/charts/top_products.png
# ... other PNG files
```

### Insights Document
```bash
open insights/insights.md
```

---

## ðŸ”§ Running Specific Queries

### Run Single Query (from python directory)

```bash
python main.py --query monthly_sales
python main.py --query top_products
python main.py --query sales_by_city
```

### Run Custom Query in Python

```python
from query_executor import QueryExecutor

executor = QueryExecutor()

# Without parameters
df = executor.execute('monthly_sales')
print(df)

# With parameters
df = executor.execute('top_products', params={'limit': 5})
print(df)
```

---

## ðŸ“š Available Queries

| Query Name | Description | Parameters |
|-----------|-------------|-----------|
| `monthly_sales` | Total sales per month | None |
| `top_products` | Top selling products | `limit` (default: 10) |
| `top_customers` | Top customers by spending | `limit` (default: 10) |
| `sales_by_city` | Sales distribution by city | None |
| `product_category_analysis` | Revenue by category | None |
| `daily_sales_trend` | Daily sales trend | None |
| `customer_purchase_frequency` | Customer purchase segments | None |
| `product_revenue_ranking` | Products by revenue | `limit` (default: 10) |
| `customer_segment_analysis` | Detailed customer segments | None |
| `quarterly_sales_comparison` | Quarterly analysis | None |
| `product_performance_metrics` | Performance KPIs | None |
| `customer_city_insights` | Customer and city insights | None |

---

## ðŸ› Troubleshooting

### Error: "Can't connect to MySQL server"

**Solution:**
1. Verify MySQL is running: `mysql -u root -p`
2. Check credentials in `config.py`
3. Ensure database `sales_analytics` exists: `SHOW DATABASES;`

### Error: "Queries file not found"

**Solution:**
1. Verify `queries/queries.json` exists
2. Check file path in `config.py`: `QUERIES_FILE = ...`
3. Ensure JSON is valid: `python -m json.tool queries/queries.json`

### Error: "Permission denied" for output files

**Solution:**
```bash
chmod -R 755 output/
chmod -R 755 insights/
```

### No data appears in charts

**Solution:**
1. Verify data is loaded: `SELECT COUNT(*) FROM sales;` in MySQL
2. Check if analysis queries return results
3. Run: `python main.py --load-sample-data` again

---

## ðŸ“Š Project Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      main.py (Entry Point)       â”‚
â”‚   Orchestrates all operations    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚analysis.py â”‚visualizationâ”‚ query_executor
â”‚          â”‚ â”‚   .py      â”‚ â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼           â–¼           â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚db.py     â”‚ â”‚queries. â”‚ â”‚config  â”‚
              â”‚          â”‚ â”‚json     â”‚ â”‚.py     â”‚
              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ MySQL Database  â”‚
            â”‚sales_analytics  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ“ Learning Points

### 1. **Config-Driven Architecture**
- SQL queries stored as JSON (not hardcoded)
- Easy to add/modify analyses without touching Python code
- Mirrors real-world analytics systems

### 2. **Safe Parameter Injection**
- Uses `%(param_name)s` placeholder syntax
- Prevents SQL injection attacks
- Supports dynamic query parameters

### 3. **Modular Design**
- Separation of concerns (DB, queries, analysis, visualization)
- Each module has single responsibility
- Easy to extend and test

### 4. **Professional Outputs**
- CSV exports for data sharing
- PNG charts for presentations
- Markdown reports for documentation

### 5. **Scalability**
- Adding new analysis: 1 query in `queries.json` + 1 function in `analysis.py`
- Supports multiple databases with config changes
- Ready for production deployment

---

## ðŸ“ Interview Talking Points

**"I built a config-driven sales analytics engine where SQL queries are stored as JSON metadata. This architecture allows Python to dynamically load and execute queries without hard-coding, making the system maintainable and scalable. The system demonstrates:**

1. **SQL proficiency** - Complex joins, aggregations, date functions
2. **Python skills** - OOP, module design, error handling
3. **Data analysis** - Trend analysis, segmentation, KPI tracking
4. **Software architecture** - Separation of concerns, config-driven design
5. **Automation** - End-to-end pipeline from query to visualization"

---

## ðŸš€ Next Steps

1. âœ… Setup complete database and load data
2. ðŸ“Š Explore generated CSV and chart files
3. ðŸ” Modify `queries.json` to add custom analyses
4. ðŸ“ˆ Create additional visualizations
5. ðŸŒ (Optional) Build Flask web dashboard
6. ðŸ“¤ (Optional) Add email report delivery

---

**Last Updated**: December 2024
**Status**: Production Ready âœ“